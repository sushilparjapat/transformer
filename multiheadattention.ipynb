{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 4\n",
    "batch_size = 1\n",
    "input_dim = 512\n",
    "d_model = 512\n",
    "x = torch.randn((batch_size , sequence_length , input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv_layer = nn.Linear(input_dim , 3*d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv = qkv_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1536])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'qkv distribution')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_val = torch.histc(qkv, bins=200, min=-3, max=3)\n",
    "x_val = np.arange(-1, 1, 0.01) * 3\n",
    "plt.bar(x_val, y_val, align='center', color=['forestgreen'])\n",
    "plt.title('qkv distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 8\n",
    "head_dim = d_model // num_heads\n",
    "qkv = qkv.reshape(batch_size, sequence_length, num_heads, 3 * head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 192])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 192])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv = qkv.permute(0, 2, 1, 3) # [batch_size, num_heads, sequence_length, 3*head_dim]\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k, v = qkv.chunk(3, dim=-1)\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = q.size()[-1]\n",
    "d_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\nodejs\\ipykernel_11536\\3717780648.py:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3701.)\n",
      "  k.T.shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 8, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4169, -1.6523,  0.6123],\n",
       "        [-1.5387,  0.2796, -1.5298]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randn(2, 3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4169, -1.5387],\n",
       "        [-1.6523,  0.2796],\n",
       "        [ 0.6123, -1.5298]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(y, -2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4169, -1.5387],\n",
       "        [-1.6523,  0.2796],\n",
       "        [ 0.6123, -1.5298]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(y, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k.transpose(-1, -2) == k.transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 64, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.transpose(-1, -2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf]],\n",
       "\n",
       "         [[-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf]],\n",
       "\n",
       "         [[-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf]],\n",
       "\n",
       "         [[-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf]],\n",
       "\n",
       "         [[-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf]],\n",
       "\n",
       "         [[-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf]],\n",
       "\n",
       "         [[-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf]],\n",
       "\n",
       "         [[-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.full(scaled.size() , float('-inf'))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., -inf, -inf, -inf],\n",
       "          [0., 0., -inf, -inf],\n",
       "          [0., 0., 0., -inf],\n",
       "          [0., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.triu(mask , diagonal = 1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2892,    -inf,    -inf,    -inf],\n",
       "        [ 0.5952, -0.3635,    -inf,    -inf],\n",
       "        [ 0.7494, -0.0447,  0.4440,    -inf],\n",
       "        [-0.4141, -0.0221, -0.2383, -0.2696]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scaled+mask)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled +=mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = F.softmax(scaled , dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.7229, 0.2771, 0.0000, 0.0000],\n",
       "        [0.4569, 0.2065, 0.3366, 0.0000],\n",
       "        [0.2072, 0.3066, 0.2469, 0.2393]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = torch.matmul(attention , v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def scaled_dot_product(q , k , v , mask = None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q,k.transpose(-1,-2)) /math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled , dim = -1)\n",
    "    values = torch.matmul(attention , v)\n",
    "    return values , attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, attention = scaled_dot_product(q, k, v, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.7229, 0.2771, 0.0000, 0.0000],\n",
       "        [0.4569, 0.2065, 0.3366, 0.0000],\n",
       "        [0.2072, 0.3066, 0.2469, 0.2393]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = values.reshape(batch_size, sequence_length, num_heads * head_dim)\n",
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = nn.Linear(d_model , d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=512, bias=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = linear_layer(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self , input_dim , d_model , num_heads):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.qkv_layer = nn.Linear(input_dim , 3*d_model)\n",
    "        self.linear_layer = nn.Linear(d_model , d_model)\n",
    "\n",
    "    def forward(self , x , mask = None):\n",
    "        batch_size , sequence_length,input_dim = x.size()\n",
    "        print(f\"x.size():{x.size()}\")\n",
    "        qkv = self.qkv_layer(x)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.permute(0, 2, 1, 3)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        print(f\"q size: {q.size()}, k size: {k.size()}, v size: {v.size()}, \")\n",
    "        values, attention = scaled_dot_product(q, k, v, mask)\n",
    "        print(f\"values.size(): {values.size()}, attention.size:{ attention.size()} \")\n",
    "        values = values.reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
    "        print(f\"values.size(): {values.size()}\")\n",
    "        out = self.linear_layer(values)\n",
    "        print(f\"out.size(): {out.size()}\")\n",
    "        return out\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size():torch.Size([30, 5, 1024])\n",
      "qkv.size(): torch.Size([30, 5, 1536])\n",
      "qkv.size(): torch.Size([30, 5, 8, 192])\n",
      "qkv.size(): torch.Size([30, 8, 5, 192])\n",
      "q size: torch.Size([30, 8, 5, 64]), k size: torch.Size([30, 8, 5, 64]), v size: torch.Size([30, 8, 5, 64]), \n",
      "values.size(): torch.Size([30, 8, 5, 64]), attention.size:torch.Size([30, 8, 5, 5]) \n",
      "values.size(): torch.Size([30, 5, 512])\n",
      "out.size(): torch.Size([30, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_dim = 1024\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "\n",
    "batch_size = 30\n",
    "sequence_length = 5\n",
    "x = torch.randn( (batch_size, sequence_length, input_dim) )\n",
    "\n",
    "model = MultiHeadAttention(input_dim, d_model, num_heads)\n",
    "out = model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sushil_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
