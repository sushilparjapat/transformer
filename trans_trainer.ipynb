{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Transformer # this is the transformer.py file\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "START_TOKEN = ''\n",
    "PADDING_TOKEN = ''\n",
    "END_TOKEN = ''\n",
    "\n",
    "kannada_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
    "                      '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', 'ˌ', \n",
    "                      'ँ', 'ఆ', 'ఇ', 'ా', 'ి', 'ీ', 'ు', 'ూ', \n",
    "                      'ಅ', 'ಆ', 'ಇ', 'ಈ', 'ಉ', 'ಊ', 'ಋ', 'ೠ', 'ಌ', 'ಎ', 'ಏ', 'ಐ', 'ಒ', 'ಓ', 'ಔ', \n",
    "                      'ಕ', 'ಖ', 'ಗ', 'ಘ', 'ಙ', \n",
    "                      'ಚ', 'ಛ', 'ಜ', 'ಝ', 'ಞ', \n",
    "                      'ಟ', 'ಠ', 'ಡ', 'ಢ', 'ಣ', \n",
    "                      'ತ', 'ಥ', 'ದ', 'ಧ', 'ನ', \n",
    "                      'ಪ', 'ಫ', 'ಬ', 'ಭ', 'ಮ', \n",
    "                      'ಯ', 'ರ', 'ಱ', 'ಲ', 'ಳ', 'ವ', 'ಶ', 'ಷ', 'ಸ', 'ಹ', \n",
    "                      '಼', 'ಽ', 'ಾ', 'ಿ', 'ೀ', 'ು', 'ೂ', 'ೃ', 'ೄ', 'ೆ', 'ೇ', 'ೈ', 'ೊ', 'ೋ', 'ೌ', '್', 'ೕ', 'ೖ', 'ೞ', 'ೣ', 'ಂ', 'ಃ', \n",
    "                      '೦', '೧', '೨', '೩', '೪', '೫', '೬', '೭', '೮', '೯', PADDING_TOKEN, END_TOKEN]\n",
    "\n",
    "english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', \n",
    "                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "                        ':', '<', '=', '>', '?', '@',\n",
    "                        '[', '\\\\', ']', '^', '_', '`', \n",
    "                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
    "                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', \n",
    "                        'y', 'z', \n",
    "                        '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_kannada = {k:v for k,v in enumerate(kannada_vocabulary)}\n",
    "kannada_to_index = {v:k for k,v in enumerate(kannada_vocabulary)}\n",
    "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
    "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('english.txt' , 'r') as file:\n",
    "    english_sentences = file.readlines()\n",
    "with open('kannada.txt', 'r') as file:\n",
    "    kannada_sentences = file.readlines()\n",
    "\n",
    "# Limit Number of sentences\n",
    "TOTAL_SENTENCES = 200000\n",
    "english_sentences = english_sentences[:TOTAL_SENTENCES]\n",
    "kannada_sentences = kannada_sentences[:TOTAL_SENTENCES]\n",
    "english_sentences = [sentence.rstrip('\\n').lower() for sentence in english_sentences]\n",
    "kannada_sentences = [sentence.rstrip('\\n') for sentence in kannada_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hes a scientist.',\n",
       " \"'but we speak the truth aur ye sach hai ke gujarat mein vikas pagal hogaya hai,'' rahul gandhi further said in banaskantha\",\n",
       " '8 lakh crore have been looted.',\n",
       " 'i read a lot into this as well.',\n",
       " \"she was found dead with the phone's battery exploded close to her head the following morning.\",\n",
       " 'how did mankind come under satans rival sovereignty?',\n",
       " 'and then i became prime minister.',\n",
       " 'what about corruption?',\n",
       " 'no differences',\n",
       " '\"\"\"the shooting of the film is 90 percent done.\"']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ಇವರು ಸಂಶೋಧಕ ಸ್ವಭಾವದವರು.',\n",
       " '\"ಆದರೆ ಸತ್ಯ ಹೊರ ಬಂದೇ ಬರುತ್ತದೆ ಎಂದು ಹೇಳಿದ ರಾಹುಲ್ ಗಾಂಧಿ, \"\"ಸೂರತ್ ಜನರು ಚೀನಾದ ಜತೆ ಸ್ಪರ್ಧೆ ನಡೆಸುತ್ತಿದ್ದಾರೆ\"',\n",
       " 'ಕಳ್ಳತನವಾಗಿದ್ದ 8 ಲಕ್ಷ ರೂ.',\n",
       " 'ಇದರ ಬಗ್ಗೆ ನಾನೂ ಸಾಕಷ್ಟು ಓದಿದ್ದೇನೆ.',\n",
       " 'ಆಕೆಯ ತಲೆಯ ಹತ್ತಿರ ಇರಿಸಿಕೊಂಡಿದ್ದ ಫೋನ್\\u200cನ ಬ್ಯಾಟರಿ ಸ್ಫೋಟಗೊಂಡು ಆಕೆ ಮೃತಪಟ್ಟಿದ್ದಾಳೆ ಎನ್ನಲಾಗಿದೆ.',\n",
       " 'ಮಾನವಕುಲವು ಸೈತಾನನ ಆಳಿಕೆಯ ಕೆಳಗೆ ಬಂದದ್ದು ಹೇಗೆ?',\n",
       " 'ನಂತರ ಪ್ರಧಾನಿ ಕೂಡ ಆಗುತ್ತೇನೆ.',\n",
       " 'ಭ್ರಷ್ಟಾಚಾರ ಏಕಿದೆ?',\n",
       " '‘ಅನುಪಾತದಲ್ಲಿ ವ್ಯತ್ಯಾಸವಿಲ್ಲ’',\n",
       " 'ಆ ಚಿತ್ರದ ಶೇ 90ರಷ್ಟು ಚಿತ್ರೀಕರಣವೂ ಈಗಾಗಲೇ ಮುಗಿದು ಹೋಗಿದೆ.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kannada_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97th percentile length Kannada: 172.0\n",
      "97th percentile length English: 178.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "PERCENTILE = 97\n",
    "print( f\"{PERCENTILE}th percentile length Kannada: {np.percentile([len(x) for x in kannada_sentences], PERCENTILE)}\" )\n",
    "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in english_sentences], PERCENTILE)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 200000\n",
      "Number of valid sentences: 164022\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = 200\n",
    "\n",
    "def is_valid_tokens(sentence, vocab):\n",
    "    for token in list(set(sentence)):\n",
    "        if token not in vocab:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def is_valid_length(sentence, max_sequence_length):\n",
    "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
    "\n",
    "valid_sentence_indicies = []\n",
    "for index in range(len(kannada_sentences)):\n",
    "    kannada_sentence, english_sentence = kannada_sentences[index], english_sentences[index]\n",
    "    if is_valid_length(kannada_sentence, max_sequence_length) \\\n",
    "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
    "      and is_valid_tokens(kannada_sentence, kannada_vocabulary):\n",
    "        valid_sentence_indicies.append(index)\n",
    "\n",
    "print(f\"Number of sentences: {len(kannada_sentences)}\")\n",
    "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kannada_sentences = [kannada_sentences[i] for i in valid_sentence_indicies]\n",
    "english_sentences = [english_sentences[i] for i in valid_sentence_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ಇವರು ಸಂಶೋಧಕ ಸ್ವಭಾವದವರು.',\n",
       " '\"ಆದರೆ ಸತ್ಯ ಹೊರ ಬಂದೇ ಬರುತ್ತದೆ ಎಂದು ಹೇಳಿದ ರಾಹುಲ್ ಗಾಂಧಿ, \"\"ಸೂರತ್ ಜನರು ಚೀನಾದ ಜತೆ ಸ್ಪರ್ಧೆ ನಡೆಸುತ್ತಿದ್ದಾರೆ\"',\n",
       " 'ಕಳ್ಳತನವಾಗಿದ್ದ 8 ಲಕ್ಷ ರೂ.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "kannada_sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "d_model = 512\n",
    "batch_size = 30\n",
    "ffn_hidden = 2048\n",
    "num_heads = 8\n",
    "drop_prob = 0.1\n",
    "num_layers = 1\n",
    "max_sequence_length = 200\n",
    "kn_vocab_size = len(kannada_vocabulary)\n",
    "\n",
    "transformer = Transformer(d_model, \n",
    "                          ffn_hidden,\n",
    "                          num_heads, \n",
    "                          drop_prob, \n",
    "                          num_layers, \n",
    "                          max_sequence_length,\n",
    "                          kn_vocab_size,\n",
    "                          english_to_index,\n",
    "                          kannada_to_index,\n",
    "                          START_TOKEN, \n",
    "                          END_TOKEN, \n",
    "                          PADDING_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (sentence_embedding): SentenceEmbedding(\n",
       "      (embedding): Embedding(69, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): SequentialEncoder(\n",
       "      (0): EncoderLayer(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNormalization()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (ffn): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNormalization()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (sentence_embedding): SentenceEmbedding(\n",
       "      (embedding): Embedding(123, 512)\n",
       "      (position_encoder): PositionalEncoding()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): SequentialDecoder(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attention): MultiHeadAttention(\n",
       "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (layer_norm1): LayerNormalization()\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (encoder_decoder_attention): MultiHeadCrossAttention(\n",
       "          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (layer_norm2): LayerNormalization()\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (ffn): PositionwiseFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm3): LayerNormalization()\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=125, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, english_sentences, kannada_sentences):\n",
    "        self.english_sentences = english_sentences\n",
    "        self.kannada_sentences = kannada_sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.english_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.english_sentences[idx], self.kannada_sentences[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextDataset(english_sentences, kannada_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164022"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"'but we speak the truth aur ye sach hai ke gujarat mein vikas pagal hogaya hai,'' rahul gandhi further said in banaskantha\",\n",
       " '\"ಆದರೆ ಸತ್ಯ ಹೊರ ಬಂದೇ ಬರುತ್ತದೆ ಎಂದು ಹೇಳಿದ ರಾಹುಲ್ ಗಾಂಧಿ, \"\"ಸೂರತ್ ಜನರು ಚೀನಾದ ಜತೆ ಸ್ಪರ್ಧೆ ನಡೆಸುತ್ತಿದ್ದಾರೆ\"')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size)\n",
    "iterator = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hes a scientist.', \"'but we speak the truth aur ye sach hai ke gujarat mein vikas pagal hogaya hai,'' rahul gandhi further said in banaskantha\", '8 lakh crore have been looted.', 'i read a lot into this as well.', 'how did mankind come under satans rival sovereignty?', 'and then i became prime minister.', 'what about corruption?', '\"\"\"the shooting of the film is 90 percent done.\"', 'the special statute', '\"then the king said to ittai the gittite, \"\"why do you also go with us? return, and stay with the king. for you are a foreigner, and also an exile. return to your own place.\"', 'what happened at the un general assembly?', 'the meeting was attended by prime minister narendra modi, home minister amit shah and defence minister rajnath singh, among others.', 'it has been under discussion for a long time.', 'buses cannot get there.', 'why then this tradition was not thought of?', 'kashmiri youth join indian army', 'basic amenities elude this village', 'off-budget borrowings of the state increased from rs853 crore in 2011-12 to rs,173 crore in 2017-18', 'during the monsoon season, the rubbish is swept on to the road by rainwater, creating problems for the traffic.', 'however, the other two, ramesh jarkiholi and mahesh kumatahalli, had not given any reason, he said.', 'how to make pasta salad?', 'he accused the modi government of ruining the countrys economy.', 'add chopped carrots and potatoes.', 'first shot', 'after the incident, police reached the spot and admitted the injured to the hospital.', 'her father gave kunti to his childless cousin kuntibhoja.', 'how to eat', 'granted, the standard of living varies from country to country.', 'for example, medical.', 'thats a fine plan.'), ('ಇವರು ಸಂಶೋಧಕ ಸ್ವಭಾವದವರು.', '\"ಆದರೆ ಸತ್ಯ ಹೊರ ಬಂದೇ ಬರುತ್ತದೆ ಎಂದು ಹೇಳಿದ ರಾಹುಲ್ ಗಾಂಧಿ, \"\"ಸೂರತ್ ಜನರು ಚೀನಾದ ಜತೆ ಸ್ಪರ್ಧೆ ನಡೆಸುತ್ತಿದ್ದಾರೆ\"', 'ಕಳ್ಳತನವಾಗಿದ್ದ 8 ಲಕ್ಷ ರೂ.', 'ಇದರ ಬಗ್ಗೆ ನಾನೂ ಸಾಕಷ್ಟು ಓದಿದ್ದೇನೆ.', 'ಮಾನವಕುಲವು ಸೈತಾನನ ಆಳಿಕೆಯ ಕೆಳಗೆ ಬಂದದ್ದು ಹೇಗೆ?', 'ನಂತರ ಪ್ರಧಾನಿ ಕೂಡ ಆಗುತ್ತೇನೆ.', 'ಭ್ರಷ್ಟಾಚಾರ ಏಕಿದೆ?', 'ಆ ಚಿತ್ರದ ಶೇ 90ರಷ್ಟು ಚಿತ್ರೀಕರಣವೂ ಈಗಾಗಲೇ ಮುಗಿದು ಹೋಗಿದೆ.', 'ವಿಶೇಷ ಕಾನೂನು', 'ಆಗ ಅರಸನು ಗಿತ್ತೀಯನಾದ ಇತ್ತೈಯನ್ನು ನೋಡಿ--ನೀನು ನಮ್ಮ ಸಂಗಡ ಬರುವದು ಯಾಕೆ? ನಿನ್ನ ಸ್ಥಳಕ್ಕೆ ಹಿಂದಿರುಗಿ ಹೋಗಿ ಅರಸನ ಸಂಗಡ ಇರು. ಯಾಕಂದರೆ ನೀನು ಸೆರೆಹಿಡಿಯಲ್ಪಟ್ಟವನಾದ ಅನ್ಯದೇಶದವನು.', 'ವಿಶ್ವ ಗೋ ಸಮ್ಮೇಳನದ ಅಂಗಳದಲ್ಲಿ ಏನೇನು ನಡೆದಿದೆ?', 'ಪ್ರಧಾನ ಮಂತ್ರಿ ನರೇಂದ್ರ ಮೋದಿ, ರಕ್ಷಣಾ ಸಚಿವ ರಾಜನಾಥ್ ಸಿಂಗ್ ಮತ್ತು ಕೇಂದ್ರ ಗೃಹ ಸಚಿವ ಅಮಿತ್ ಷಾ ಅವರು ಮಸೂದೆಯ ಬಗ್ಗೆ ಸಾರ್ವಜನಿಕ ಚರ್ಚೆ ಗೆ ಬರುವಂತೆ ಸಂಘ ಸವಾಲು ಹಾಕಿದೆ.', 'ಎಂಬುದು ಬಹಳ ದೀರ್ಘ ಕಾಲದಿಂದಲೂ ಚರ್ಚಿತವಾಗುತ್ತಿರುವ ವಿಷಯ.', 'ಇಲ್ಲಿಗೆ ಬರಲು ಬಸ್ ಸೌಕರ್ಯವೂ ಇಲ್ಲ.', 'ಆ ಪರಂಪರೆ ಯಾಕೆ ಮುನ್ನೆಲೆಗೆ ಬರಲಿಲ್ಲ?', 'ಭಾರತೀಯ ಸೇನೆ ಸೇರಲು ಮುಗಿಬೀಳುತ್ತಿರುವ ಕಾಶ್ಮೀರಿ ಯುವಕರು !', 'ಕುಗ್ರಾಮವಾದ ಈ ಹಳ್ಳಿಯಲ್ಲಿ ಮೂಲಭೂತ ಸೌಕರ್ಯಗಳು', 'ರಾಜ್ಯದ ಬಜೆಟ್ ಯೇತರ ಸಾಲವು 2011-12ರಲ್ಲಿದ್ದ 1,853ಕೋಟಿ ರೂಪಾಯಿಯಿಂದ 2017-18ರಲ್ಲಿ 13,173 ಕ್ಕೆ ಏರಿಕಯಾಗಿದೆ.', 'ಮಳೆಗಾಲದಲ್ಲಿ ಕೊಳಚೆ ನೀರಿನೊಂದಿಗೆ ಮಳೆನೀರು ರಸ್ತೆಯಲ್ಲಿಯೇ ಮಡುಗಟ್ಟಿ ನಿಂತು ಸೊಳ್ಳೆಗಳ ಹೆಚ್ಚಳಕ್ಕೆ ಕಾರಣವಾಗುತ್ತಿದೆ.', 'ಯಾವುದೇ ಕಾರಣ ನೀಡದೆ ರಮೇಶ್ ಜಾರಕಿಹೊಳಿ ಮತ್ತು ಮಹೇಶ್ ಕಮಟಹಳ್ಳಿ ಗೈರು ಹಾಜರಾಗಿದ್ದಾರೆ ಎಂದು ಮಾಹಿತಿ ನೀಡಿದ್ದಾರೆ.', '\"ಹೇಗೆ \"\"ಗೂಳಿಕಾಳಗ\"\" ಒಂದು ಸಲಾಡ್ ತಯಾರು ಹೇಗೆ?\"', 'ಅದ್ರಲ್ಲೂ ಪ್ರಮುಖವಾಗಿ ದೇಶದ ಆರ್ಥಿಕತೆ ಪಾತಾಳಕ್ಕೆ ಕುಸಿದಿರೋದಕ್ಕೆ ಮೋದಿ ಸರ್ಕಾರವೇ ಸರ್ಕಾರ ಅಂತಾ ಟೀಕಿಸುತ್ತಿದ್ದಾರೆ.', 'ಅವರಿಗೆ ಕತ್ತರಿಸಿದ ಪಾರ್ಸ್ಲಿ ಮತ್ತು ತುಳಸಿ ಸೇರಿಸಿ.', 'ಮೊದಲ ಚಿತ್ರ ಶೂಟಿಂಗ್', 'ಅಪಘಾತದ ನಡೆದ ಕೂಡಲೇ ಮಾಹಿತಿ ಪಡೆದು ಸ್ಥಳಕ್ಕೆ ಆಗಮಿಸಿದ ಪೋಲಿಸರು ಗಾಯಗೊಂಡವರನ್ನು ಆಸ್ಪತ್ರೆ ದಾಖಲಿಸಿದ್ದಾರೆ.', 'ಆಕೆಯ ತಂದೆ ತನ್ನ ಮಕ್ಕಳಿಲ್ಲದ ಸೋದರಸಂಬಂಧಿ ಕುಂತಿಭೋಜನಿಗೆ ಕುಂತಿಯನ್ನು ಕೊಟ್ಟರು.', 'ಆಹಾರ ಬೇಯಿಸುವುದು ಹೇಗೆ', 'ಜೀವನಮಟ್ಟವು ದೇಶದಿಂದ ದೇಶಕ್ಕೆ ಬದಲಾಗುತ್ತದೆ ನಿಜ.', 'ಉದಾಹರಣೆಗೆ, ಖಗೋಳಶಾಸ್ತ್ರ.', 'ಇದೊಂದು ಉತ್ತಮ ಯೋಜನೆ.')]\n",
      "[(\"you don't know this.\", 'you are respected in society.', 'is this pic real?', '\"\"\"felicitations to all for the foundation laying of ram temple in ayodhya.\"', 'she looked stunningly beautiful in that', '{ -brand-name-nightly } blog', 'it was consistent.', 'case has been registered in malpe police station.', 'they still exist to this day.', 'breaking up isnt easy', 'students should abide by the rules.', 'we try to understand her well.', 'then the angel of yahweh commanded gad to tell david that david should go up, and raise an altar to yahweh in the threshing floor of ornan the jebusite.', 'for example, he forbids sexual immorality, idolatry, stealing, and drunkenness.', 'it is also a famous tourist destination', 'doctors and other persons concerned have been questioned.', 'but in politics.', 'to understand gods actions, we need to answer three questions: (1) who starts the war?', '14,000 crores.', 'what are those words?', 'shivakumars assumption of office as president of karnataka pradesh congress committee (kpcc).', 'now we were notified that we would receive the magazines in russian only.', 'they are found along coastlines around the world except antarcticas.', 'bill clinton went on to become president.', 'the culmination of the three stories towards the end. gives a new dimension to the film as a whole and concludes shuddhi.', 'while individuals may be allowed to die, god will never allow the extermination of his people as a whole.', '(the author is an educationist)', 'therefore i will not refrain my mouth. i will speak in the anguish of my spirit. i will complain in the bitterness of my soul.', 'are they hungry for knowledge?', 'the door did not open.'), ('ಈ ಬಗ್ಗೆ ನೀವಿನ್ನು ತಿಳಿದಿಲ್ಲ ಎ .', 'ಸಮಾಜದಲ್ಲಿ ಗೌರವವಿರುತ್ತದೆ.', 'ಈ ಫೋಟೋ ವಾಸ್ತವೋ, ಅಸಲಿಯೋ ?', \"'ಅಯೋಧ್ಯೆಯ ರಾಮ ದೇವಾಲಯದ ಅಡಿಪಾಯ ಹಾಕಿದ್ದಕ್ಕಾಗಿ ಎಲ್ಲರಿಗೂ ಶುಭಾಶಯಗಳು.\", 'ಅವಳು ಅಥವಾ ಆತ ನೋಡಲು ತುಂಬಾ ಸುಂದರ', 'ನೈಟ್ಲಿ ಬ್ಲಾಗ್', 'ಇದು ಸಂಕೇತವಾಗಿತ್ತು.', 'ಪ್ರಕರಣ ಮಳವಳ್ಳಿ ಪೊಲೀಸ್ ಠಾಣೆಯಲ್ಲಿ ದಾಖಲಾಗಿದೆ.', 'ಅಂತೆಯೇ ಅವರು ಇಂದಿಗೂ ಪ್ರಸ್ತುತವಾಗಿದ್ದಾರೆ.', 'ವೈರಾಗ್ಯ ಸುಲಭವಲ್ಲ', 'ವಿದ್ಯಾರ್ಥಿಗಳು ಕೂಡಾ ಶಿಸ್ತು ಪಾಲಿಸಬೇಕು.', '\"\"\" ಅವರೊಂದಿಗೆ ಅವನಿಗೆ ವಿವರವಾಗಿ ಅರ್ಥಮಾಡಿಕೊಳ್ಳಲು ಪ್ರಯತ್ನಿಸೋಣ.\"', 'ಆಗ ಕರ್ತನ ದೂತನು ಗಾದನಿಗೆ--ದಾವೀದನು ಹೋಗಿ ಯೆಬೂಸಿಯನಾದ ಒರ್ನಾನನ ಕಣದಲ್ಲಿ ಕರ್ತನಿಗೆ ಬಲಿಪೀಠವನ್ನು ಕಟ್ಟುವ ಹಾಗೆ ದಾವೀದನಿಗೆ ಹೇಳು ಅಂದನು.', 'ಬೈಬಲಿನಲ್ಲಿ ಯೆಹೋವನು ನಮಗೆ ಸ್ಪಷ್ಟ ಆಜ್ಞೆಗಳನ್ನು ಕೊಟ್ಟಿದ್ದಾನೆ.', 'ಇದೊಂದು ಬಹು ಜನಪ್ರಿಯವಾದ ವಿಹಾರ ತಾಣವಾಗಿದೆ', 'ಶಸ್ತ್ರ ಚಿಕಿತ್ಸೆ ಮಾಡಿದ ವೈದ್ಯರು ಮತ್ತು ಇತರ ಸಿಬ್ಬಂದಿಯನ್ನು ವಿಚಾರಣೆಗೆ ಒಳಪಡಿಸಿದ್ದಾರೆ.', 'ಆದರೆ ರಾಜಕೀಯದಲ್ಲಿರುತ್ತೇನೆ.', '( ನೆಹೆಮಿಾಯ 9: 17) ಇದನ್ನು ಅರ್ಥಮಾಡಿಕೊಳ್ಳಲು ಈ ಮೂರು ಪ್ರಶ್ನೆಗಳಿಗೆ ಉತ್ತರ ತಿಳಿಯಿರಿ: (1) ಯುದ್ಧ ಆರಂಭಿಸುವವರು ಯಾರು?', '14,000 ಒಟ್ಟುಗೂಡಿತು.', 'ಈ ಶಬ್ದಗಳು ಯಾವುವು?', 'ಕೊನೆಗೂ ಡಿಕೆ ಶಿವಕುಮಾರ್ ಅವರನ್ನ ಕರ್ನಾಟಕ ಪ್ರದೇಶ ಕಾಂಗ್ರೆಸ್ (ಕೆಪಿಸಿಸಿ) ಅಧ್ಯಕ್ಷರನ್ನಾಗಿ ಆಯ್ಮೆ ಮಾಡಿದೆ.', 'ಪತ್ರಿಕೆಯು ನಿಷೇಧಿಸಲ್ಪಟ್ಟಿತ್ತು, ಆದರೆ ಇತರ ಸ್ಥಳಗಳಿಂದ ಗುಟ್ಟಾಗಿ ನಾವು ಪತ್ರಿಕೆಗಳನ್ನು ಪಡೆಯುತ್ತಿದ್ದೆವು.', 'ಅಂಟಾರ್ಟಿಕಾ ಖಂಡದ ಹೊರತುಪಡಿಸಿ ಅವು ವಿಶ್ವದಾದ್ಯಂತ ಕಂಡುಬರುತ್ತವೆ.', 'ಇವರ ನಂತರ ಬಿಲ್ ಕ್ಲಿಂಟನ್ ಅಧ್ಯಕ್ಷ ಪಟ್ಟ ಅಲಂಕರಿಸಿದ್ದರು.', 'ಕೊನೆಯಲ್ಲಿ ಮೂರು ಕಥೆಗಳ ಪರಾಕಾಷ್ಠೆ. ಒಟ್ಟಾರೆಯಾಗಿ ಚಿತ್ರಕ್ಕೆ ಹೊಸ ಆಯಾಮವನ್ನು ನೀಡುತ್ತದೆ ಮತ್ತು ಸುಧಿಯನ್ನು ಮುಕ್ತಾಯಗೊಳಿಸುತ್ತದೆ.', 'ಕೆಲವು ವ್ಯಕ್ತಿಗಳು ಸಾಯುವಂತೆ ಅನುಮತಿಸಲ್ಪಡುವುದಾದರೂ, ತನ್ನ ಜನರೆಲ್ಲರೂ ಸಂಪೂರ್ಣವಾಗಿ ನಿರ್ಮೂಲರಾಗುವಂತೆ ದೇವರು ಎಂದಿಗೂ ಅನುಮತಿಸುವುದಿಲ್ಲ.', '(ಲೇಖಕರು ಶಿಕ್ಷಣತಜ್ಞರು)', 'ಆದದರಿಂದ ನಾನು ನನ್ನ ಬಾಯಿಯನ್ನು ಮುಚ್ಚು ವದಿಲ್ಲ. ನಾನು ಆತ್ಮ ವೇದನೆಯಿಂದ ಮಾತನಾಡು ವೆನು. ನನ್ನ ಮನೋವ್ಯಥೆಯಲ್ಲಿ ನಾನು ಗುಣುಗುಟ್ಟು ವೆನು.', 'ನಿಂಗೆ ಜ್ಞಾನದ ಹಸಿವು ನೀಗಸ್ತಾರೆ ?', 'ಅಂಗಳದ ಬಾಗಿಲು ಹಾಕಿರಲಿಲ್ಲ.')]\n",
      "[('i am non-vegetarian.', 'most of the government schools lack the teachers.', 'to the fans.', 'during the investigation, it was found that the 130 activists were in regular contact with the jmb leadership, he said.', 'it is 260 km away from mumbai city.', 'not everything happens as we expect.', 'what are you talking?', 'that young couple certainly started their marriage off on the best of foundations.', 'abbey waterfall flows from a height of 60 feet.', 'the treatment depends largely on the type and stage of the cancer.', 'i learned how to cook.', 'is coconut oil harmful?', 'may i answer?', 'what is love?', 'symptoms include rashes, diarrhea, vomiting, stomach cramps and bloating.', 'during 2015, they plan on introducing two new amg vehicles the c 63 s and gt s supercar', 'candidates belonging to st/sc, pwd category are exempted from paying any fee.', 'i love', 'you cant have everything always.', 'the death toll of coronavirus rose to 718 as 37 casualties were reported in 24 hours', 'his life was devoted to the service of the country.', 'he lost his father at an early age.', 'the vehicle is completely burnt.', 'but it was cancelled at the last moment.', 'many people are dead due to floods and extensive damage to property has occurred.', 'the scheme will be rolled out in the next couple of months.', 'what is not nice?', 'and he said, bring me a new cruse, and put salt therein. and they brought it to him.', 'the tvs entorq 125 will be up against the likes of honda activa, suzuki access and others', 'he handed over the documents for the 900 sq ft plot to nagar panchayat chairman zahir farooqui.'), ('ನಾನೇನು ಸಂಪೂರ್ಣ ಸಸ್ಯಾಹಾರಿ ಅಲ್ಲ.', 'ಬಹುತೇಕ ಸರ್ಕಾರಿ ಶಾಲೆಗಳಲ್ಲಿ ಮೂಲಭೂತ ಸೌಕರ್ಯಗಳೇ ಇಲ್ಲದಿರುವುದು ಕಂಡುಬಂದಿದೆ.', 'ಎಂಬ ಅಭಿಮಾನಿಗಳಿಗೆ ಕಾಡುತ್ತಿದೆ.', 'ಜೆಎಂಬಿ ನಾಯಕತ್ವದ ಜತೆ 130 ಕಾರ್ಯಕರ್ತರು ನಿಕಟ ಸಂಪರ್ಕದಲ್ಲಿರುವುದು ತನಿಖಾ ಹಂತದಲ್ಲಿ ಬೆಳಕಿಗೆ ಬಂದಿದೆ ಎಂದು ತಿಳಿಸಿದರು.', 'ಇದು ರಾಜ್ಯದ ರಾಜಧಾನಿಯಾದ ಮುಂಬೈನಿಂದ ಸುಮಾರು 260 ಕಿಮೀ ದೂರದಲ್ಲಿದೆ.', 'ಎಲ್ಲವೂ ನಾವು ಅಂದುಕೊಂಡಂತೆಯೇ ಆಗುವುದಿಲ್ಲ.', '\"\"\"ಏನೆಲ್ಲ ಮಾತಾಡತಾನೆ?\"', 'ಕೊನೆಯದಾಗಿ, ಈ ಘಟನೆಗಳು ಯೋಸೇಫ ಮರಿಯ ಇಬ್ಬರಿಗೂ ಪ್ರಾಮಾಣಿಕವೂ ಮುಕ್ತವೂ ಆದ ಸಂವಾದವು ಎಷ್ಟು ಮಹತ್ವ ಎಂಬ ವಿಷಯದಲ್ಲಿ ಹೆಚ್ಚನ್ನು ಕಲಿಸಿದ್ದಿರಬೇಕು.', '60 ಅಡಿ ಎತ್ತರದಿಂದ ನೀರು ಧರೆಗೆ ಧುಮ್ಮಿಕ್ಕುತ್ತದೆ.', 'ಚಿಕಿತ್ಸೆಯ ವಿಧಾನದ ಆಯ್ಕೆ ಹೆಚ್ಚಾಗಿ ರೋಗದ ಹಂತ ಮತ್ತು ಸ್ವರೂಪವನ್ನು ಅವಲಂಬಿಸಿರುತ್ತದೆ.', 'ಅಷ್ಟುಇಷ್ಟು ಅಡುಗೆ ಮಾಡುವುದನ್ನು ಕಲಿತುಬಿಟ್ಟೆ.', 'ಕಾರ್ನ್ ಎಣ್ಣೆ ಉಪಯುಕ್ತವಾಗಿದೆ?', '\"ಪ್ರಶ್ನೆ, \"\"ನಾನು ಉತ್ತರಿಸಬೇಕೇ?\"', 'ಪ್ರೀತಿ ಅಂದರೆ ಇದೇನಾ?', 'ರೋಗಲಕ್ಷಣಗಳು ಕ್ಯಾಂಪಿಂಗ್, ಭಾರಿ ಅವಧಿ, ಹೆಪ್ಪುಗಟ್ಟುವಿಕೆ, ಕೆಳ ಹೊಟ್ಟೆ ನೋವು, ಮತ್ತು ಉಬ್ಬುವುದು.', 'ಈ ಸಾಲಿಗೆ ಪ್ರಸಕ್ತ ವರ್ಷದಲ್ಲಿ ಎಎಂಜಿ ಸಿ 63 ಎಸ್ ಮತ್ತು ಜಿಟಿ ಎಸ್ ಸೂಪರ್ ಕಾರು ಸೇರ್ಪಡೆಯಾಗಲಿದೆ', 'ಎಸ್ಸಿ, ಎಸ್ಟಿ / ಪಿಡಬ್ಲ್ಯೂಡಿ ವಿಭಾಗಗಳಿಗೆ ಸೇರಿದ ಅಭ್ಯರ್ಥಿಗಳು ಅರ್ಜಿ ಪ್ರಕ್ರಿಯೆ ಶುಲ್ಕದಿಂದ ವಿನಾಯಿತಿ ಪಡೆದಿರುತ್ತಾರೆ.', 'ನಾನು ಪ್ರೀತಿಸಿದ್ದೇನೆ.', 'ಯಾವಾಗಲೂ ಎಲ್ಲಾ ಪದಾರ್ಥಗಳನ್ನು ಹೊಂದಿಲ್ಲ.', 'ದೇಶಾದ್ಯಂತ ಕರೋನಾ ಸೋಂಕಿತರ ಸಂಖ್ಯೆ 23 ಸಾವಿರಕ್ಕೂ ಹೆಚ್ಚಿದ್ದು, ಒಟ್ಟು ಈವರೆಗೆ 718 ಜನರು ಮೃತಪಟ್ಟಿದ್ದಾರೆ', 'ಅವರ ಜೀವನವನ್ನು ರಾಷ್ಟ್ರ ಸೇವೆಗೆ ಮಾತ್ರ ಮುಡಿಪಾಗಿಟ್ಟಿದ್ದರು ಎಂದು ತಿಳಿಸಿದರು.', 'ಬಾಲ್ಯದಲ್ಲೇ ತಂದೆಯನ್ನು ಕಳೆದುಕೊಂಡರು.', 'ಕಾರು ಸಂಪೂರ್ಣ ಬೆಂಕಿಗೆ ಆಹುತಿ ಆಗಿದೆ.', 'ಆದರೆ ಕೊನೇ ಕ್ಷಣದಲ್ಲಿ ತಮ್ಮ ನಿರ್ಧಾರದಿಂದ ಹಿಂದೆ ಸರಿದಿದ್ದಾರೆ.', 'ಪ್ರವಾಹದಿಂದ ಬಹಳಷ್ಟು ಆಸ್ತಿ ನಷ್ಟವಾಗಿದ್ದು, ಜನರು ಸಂಕಷ್ಟದಲ್ಲಿದ್ದಾರೆ.', 'ಮುಂದಿನ ಕೆಲವು ತಿಂಗಳಲ್ಲಿ ಈ ಯೋಜನೆಯನ್ನು ಪ್ರಕಟಿಸಲಾಗುವುದು.', 'ಚೆಂದ ಇಲ್ಲದಿದ್ದರೇನು?', 'ಅದಕ್ಕ ವನು--ನನ್ನ ಬಳಿಗೆ ಹೊಸ ಗಡಿಗೆಯನ್ನು ತಕ್ಕೊಂಡು ಬಂದು ಅದರಲ್ಲಿ ಉಪ್ಪು ಹಾಕಿರಿ ಅಂದನು. ಅವರು ಅದನ್ನು ಅವನ ಬಳಿಗೆ ತಕ್ಕೊಂಡು ಬಂದರು.', 'ಪ್ರಮುಖವಾಗಿಯೂ ಹೋಂಡಾ ಆಕ್ಟಿವಾ 125, ಸುಜುಕಿ ಆಕ್ಸೆಸ್ 125 ಹಾಗೂ ಮಹೀಂದ್ರ ಗಸ್ಟೊ 125 ಮಾದರಿಗಳಿಗೆ ಟಿವಿಎಸ್ ನೂತನ ಸ್ಕೂಟರ್ ಪ್ರತಿಸ್ಪರ್ಧಿಯಾಗಲಿದೆ', '900 ಚದರ ಅಡಿ ಜಾಗದ ಭೂ ದಾಖಲೆಗಳನ್ನು ಅವರು ನಗರ ಪಂಚಾಯತ್ ಅಧ್ಯಕ್ಷ ಜಹೀರ್ ಫಾರೂಕಿ ಅವರಿಗೆ ಹಸ್ತಾಂತರಿಸಿದರು.')]\n",
      "[('the engine is mated to a six-speed gearbox with a slip and assist clutch', 'this is what he has said.', 'but it is not taking off.', \"conflicting reports on amitabh bachchan's health confuse fans\", 'howsoever powerful.', 'the conversation thereafter went as follows:', 'what is the opposition doing?', 'best of luck to all team members.', 'but it is very expensive.', \"shah rukh khan's next film is titled sanki and will be directed by tamil director atlee.\", 'thats exactly what organizations are saying.', 'bike rider killed in motorcycle-tanker collision', 'students need not worry about it, he said.', 'there is no risk to anyone.', 'the matter had created uproar across the state.', 'parents are overjoyed to see the success of their children.', 'elections will be held soon.', 'to and fro vehicular traffic to the hill from uttanahalli road side has been completely banned.', 'do you leave?', 'define your goals and objectives.', \"what's up.\", 'how long will you take for completing the investigation?', 'there are two engine options.', 'the film in question has not yet received the certificate from censor board.', '\"even chhatrapati shivaji maharaj faced opposition from his own family,\"\" he said.\"', 'how to make a cake at home?', 'there was no harm to any passenger due to the fire.', 'they too moved their forces.', 'development has taken a hit in the state.', 'and this can be done by:'), ('ಈ ಎಂಜಿನ್ ಅನ್ನು 6- ಸ್ಪೀಡ್ ಗೇರ್ಬಾಕ್ಸ್ಗೆ ಅಸಿಸ್ಟ್ ಮತ್ತು ಸ್ಲಿಪ್ಪರ್ ಕ್ಲಚ್ನೊಂದಿಗೆ ಜೋಡಿಸಲಾಗಿದೆ', 'ಈ ಮೂಲಕ ತಾವೇನೆಂಬುದನ್ನು ತಿಳಿಸಿದ್ದಾರೆ.', 'ಆದರೆ, ಅದನ್ನು ಬಿಡುಗಡೆ ಮಾಡುತ್ತಿಲ್ಲ.', 'ಅಭಿಮಾನಿಗಳಲ್ಲಿ ಗೊಂದಲ ಸೃಷ್ಟಿಸಿದ ಅಮಿತಾಬ್ ಬಚ್ಚನ್ ಅನಾರೋಗ್ಯ ಸುದ್ದಿ', 'ಷ್ಟೇ ಬಲಶಾಲಿ ಆಗಿರಲಿ.', 'ಆನಂತರ ನಡೆದ ಸಂಭಾಷಣೆಯ ಸಾರಾಂಶ ಹೀಗಿದೆ.', 'ವಿರೋಧ ಪಕ್ಷದವರ ಕೆಲಸ ಏನಿದೆ?', 'ತಂಡದ ಸದಸ್ಯರಿಗೆಲ್ಲಾ ಅದೃಷ್ಟ ತಂದುಕೊಡುತ್ತವೆ.', 'ಆದರೆ ಆರ್ಥಿಕ ದೃಷ್ಟಿಯಿಂದ ಬಹಳ ದುಬಾರಿಯಾಗಿರುತ್ತದೆ.', 'ಶಾರುಖ್ ಖಾನ್ ಅವರ ಮುಂದಿನ ಚಲನಚಿತ್ರವನ್ನು ತಮಿಳು ನಿರ್ದೇಶಕ ಅಟ್ಲೀ ನಿರ್ದೇಶನ ಮಾಡಲಿದ್ದಾರೆ.', 'ಹಾಗೆಂದು ಆ ಸಂಸ್ಥೆಯೇ ಹೇಳಿಕೊಳ್ಳುತ್ತಿದೆ.', 'ಕಬ್ಬು ಸಾಗಿಸುತ್ತಿದ್ದ ಲಾರಿ ಹಾಗೂ ಬೈಕ್ ನಡುವೆ ಡಿಕ್ಕಿ : ಸವಾರ ಸಾವು', 'ಇದರ ಬಗ್ಗೆ ಯಾವುದೇ ಆತಂಕ ಬೇಡ ಎಂದು ವಿದ್ಯಾರ್ಥಿಗಳಿಗೆ ತಿಳಿಸಿದರು.', 'ಯಾರಿಗೂ ಅಂತಹ ಅಪಾಯಗಳಾಗಿಲ್ಲ ಎಂದರು.', 'ಈ ಸುದ್ದಿ ರಾಜ್ಯಾದ್ಯಂತ ಚರ್ಚೆಗೆ ಕಾರಣವಾಗಿತ್ತು.', 'ಪ್ರತಿ ಹೆತ್ತವರಿಗೂ ಅವರವರ ಮಕ್ಕಳ ಸಾಧನೆ ನೋಡೋ ಖುಷಿ ಇದ್ದೇ ಇರುತ್ತೆ.', 'ಚುನಾವಣೆ ಇನ್ನೇನು ಸಧ್ಯದಲ್ಲೇ ನಡೆಯಲಿದೆ.', 'ಉತ್ತನಹಳ್ಳಿ ರಸ್ತೆಯ ಕಡೆಯಿಂದ ಚಾಮುಂಡಿ ಬೆಟ್ಟಕ್ಕೆ ಬರುವ ಮತ್ತು ಹೋಗುವ ವಾಹನಗಳಿಗೆ ಸಂಚಾರವನ್ನು ಸಂಪೂರ್ಣವಾಗಿ ನಿರ್ಬಂಧಿಸಲಾಗಿದೆ.', 'ಬಿಡಲಿಕ್ಕೆ ಆಗುತ್ತಾ?', 'ನಿಮ್ಮ ಗುರಿ ಮತ್ತು ಉದ್ದೇಶಗಳನ್ನು ಗುರುತಿಸಿ.', 'ಏನು ಉರುಳೇ.', 'ತನಿಖೆಯನ್ನು ಪೂರ್ಣಗೊಳಿಸಲು ನಿಮಗೆ ಇನ್ನೂ ಎಷ್ಟು ಸಮಯ ಬೇಕು?', 'ಎರಡು ಎಂಜಿನ್ ಆಯ್ಕೆಗಳಿವೆ.', 'ಸೆನ್ಸಾರ್ ಮಂಡಳಿಯಿಂದ ಈ ಸಿನಿಮಾಗೆ ಇನ್ನೂ ಪ್ರಮಾಣಪತ್ರ ನೀಡಿಲ್ಲ.', 'ಛತ್ರಪತಿ ಶಿವಾಜಿ ಕೂಡ ತಮ್ಮದೇ ಕುಟುಂಬದಿಂದಲೇ ವಿರೋಧವನ್ನು ಎದುರಿಸಿದ್ದರು.', 'ಹೇಗೆ ಮನೆಯಲ್ಲಿ ಒಂದು ಕಾರ್ಟೂನ್ ರಚಿಸಲು?', 'ಬೆಂಕಿ ಅವಘಡದಲ್ಲಿ ಪ್ರಯಾಣಿಕರ ಪ್ರಾಣಕ್ಕೆ ಹಾನಿಯಾಗಿಲ್ಲ.', 'ತಮ್ಮ ಅಧಿಕಾರವನ್ನು ಚಲಾಯಿಸಿದ್ದರು ಕೂಡಾ.', 'ರಾಜ್ಯದಲ್ಲಿ ಅಭಿವೃದ್ಧಿ ಪರ್ವ ಬಂದಿದೆ.', 'ಮತ್ತು ನೀವು ಇದನ್ನು ಪರಿಹರಿಸಬಹುದು:')]\n",
      "[('a proposal has been made.', 'but the government is unmoved.', 'the programme was attended by students and teachers of the school.', 'they taught me much about the true holy father in heaven, jehovah god.', 'what we can do', 'the bjp is trying to gain a strong foothold in the state.', 'farmers are in distress all over the country.', 'but euphoria, relief, and achievement likewise provoke emotional tears in this case, tears of joy.', 'and to pass by you into macedonia, and to come again out of macedonia unto you, and of you to be brought on my way toward judaea.', 'in case of an attack, we need to respond swiftly to minimise the damage.', 'for unknown reasons.', 'community spread', 'which board?', 'there are 14 girls and 12 junior players.', 'preparing for the role', 'recipe: banana blossom salad', 'do not isolate yourself from your faithful christian brothers and sisters.', 'patient with leukaemia disease.', 'the total length of the highway road is 250 km.', 'the governors post is a constitutional post.', 'development and growth', 'it was even found among the ones he had chosen as apostles!', 'in their hands lies the future of india.', 'government high school', 'they stay in their own world.', 'you cant be regretful.', 'location: ranga rao road, near shankar mutt, shankarapura, near basavanagudi, bangalore', \"that's all humbug.\", 'they were all there.', 'he was keen to learn english also.'), ('ಪ್ರಸ್ತಾವನೆ ಸಲ್ಲಿಸಿತ್ತು.', 'ಆದರೆ ಈ ಸರ್ಕಾರ ಸದ್ಯ ಅತಂತ್ರದಲ್ಲಿದೆ.', 'ಈ ಕಾರ್ಯಕ್ರಮದಲ್ಲಿ ಶಿಕ್ಷಕ ವೃಂದ ಹಾಗೂ ವಿದ್ಯಾರ್ಥಿಗಳು ಭಾಗಿಯಾಗಿದ್ದರು.', 'ಅವರು ನನಗೆ ಸ್ವರ್ಗದಲ್ಲಿರುವ ನಿಜವಾದ ಪವಿತ್ರ ತಂದೆ ಯೆಹೋವ ದೇವರ ಬಗ್ಗೆ ಬಹಳಷ್ಟನ್ನು ಕಲಿಸಿದರು.', 'ನಾವೇನು ಮಾಡಬಹುದು ?', 'ರಾಜ್ಯದಲ್ಲಿ ಬಿಜೆಪಿ ಅಧಿಕಾರ ಪಡೆದುಕೊಳ್ಳಲು ಶಥಾಯ ಗಥಾಯ ಪ್ರಯತ್ನ ಮಾಡುತ್ತಿದೆ', 'ದೇಶಾದ್ಯಂತ ರೈತರು ಸಂಕಷ್ಟದಲ್ಲಿದ್ದಾರೆ.', 'ಭಾವನಾತ್ಮಕ ಕಣ್ಣೀರು ಉಕ್ಕಿ ಬರಲು ಅನೇಕ ಕಾರಣಗಳಿವೆ.', 'ತರುವಾಯ ನಿಮ್ಮ ಮಾರ್ಗವಾಗಿ ಮಕೆದೋನ್ಯಕ್ಕೆ ಹೋಗಿ ತಿರಿಗಿ ಮಕೆದೋನ್ಯದಿಂದ ನಿಮ್ಮ ಬಳಿಗೆ ಬಂದು ನಿಮ್ಮಿಂದ ಯೂದಾಯಕ್ಕೆ ಸಾಗಕಳುಹಿಸಲ್ಪಡುವಂತೆಯೂ ಯೋಚಿಸಿದ್ದೆನು.', 'ದಾಳಿಯ ಸಂದರ್ಭದಲ್ಲಿ ಹಾನಿಯನ್ನು ಕನಿಷ್ಠಗೊಳಿಸಲು ನಾವು ಚುರುಕಾಗಿ ಕಾರ್ಯಾಚರಿಸಬೇಕಾಗುತ್ತದೆ.', 'ಸ್ಪಷ್ಟೀಕರಿಸದ ಕಾರಣಗಳಿಗಾಗಿ', 'ಸಮುದಾಯ ಹರಡುವಿಕೆ', 'ಯಾರಿಗೆ ಯಾವ ಮಂಡಳಿ?', 'ಇವುಗಳಲ್ಲಿ 14 ಗಂಡು, 12 ಹೆಣ್ಣು ಚಿರತೆ ಸೇರಿವೆ.', 'ಪಾತ್ರಕ್ಕಾಗಿ ತಯಾರಿ', '\"ಪಾಕವಿಧಾನ: ಹೂಕೋಸು \"\"ಆಲೂಗಡ್ಡೆ\"\" ಸಲಾಡ್\"', 'ನಂಬಿಗಸ್ತ ಸಹೋದರ ಸಹೋದರಿಯರಿಂದ ನಿಮ್ಮನ್ನು ಪ್ರತ್ಯೇಕಿಸಿಕೊಳ್ಳಬೇಡಿ.', 'ತೀವ್ರತರವಾದ ಲ್ಯುಕೇಮಿಯಾ ಬಳಲುತ್ತಿರುವ ರೋಗಿಗಳು.', 'ರಸ್ತೆಯಲ್ಲಿ ಒಟ್ಟು ಅಗಲ - 250 ಮೀಟರ್.', 'ರಾಜ್ಯಪಾಲರದು ಸಂವಿಧಾನಾತ್ಮಕ ಹುದ್ದೆ.', 'ಅಭಿವೃದ್ಧಿ ಮತ್ತು ಅನಾರೋಗ್ಯ', 'ಯೇಸು ಸಾಯುವ ದಿನದ ವರೆಗೂ ಅವರು ಹೆಬ್ಬಯಕೆಯನ್ನು ತೋರ್ಪಡಿಸಿದರು.', 'ಇವರ ಆಟದ ಮೇಲೆ ಭಾರತದ ಭವಿಷ್ಯ ನಿಂತಿದೆ.', 'ಸಮಸ್ಯೆಗಳ ಆಗರ ಸರ್ಕಾರಿ ಪ್ರೌಢಶಾಲೆ', 'ಇವರು ತಮ್ಮದೇ ಆಗಿರುವ ಲೋಕದಲ್ಲಿ ವಿಹರಿಸುತ್ತಾ ಇರುವರು.', 'ನಿಮಗೆ ಕ್ಷಮಿಸುವ ಮನಸ್ಸಿಲ್ಲದಿರಬಹುದು.', 'ಸ್ಥಳ : ಜಕ್ಕಸಂದ್ರ, ಸರ್ಜಾಪುರ ರಸ್ತೆ, ಬೆಂಗಳೂರು', 'ಅದೆಲ್ಲ ಗಿಮಿಕ್ ಅಷ್ಟೆ.', 'ಅವರೆಲ್ಲರೂ ಇದ್ದರು.', 'ಅವರಿಗೆ ಇಂಗ್ಲಿಷ್ ಕಲಿಯುವುದಕ್ಕೆ ತುಂಬಾ ಆಸೆ ಇತ್ತು.')]\n"
     ]
    }
   ],
   "source": [
    "for batch_num, batch in enumerate(iterator):\n",
    "    print(batch)\n",
    "    if batch_num > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "criterian = nn.CrossEntropyLoss(ignore_index=kannada_to_index[PADDING_TOKEN],\n",
    "                                reduction='none')\n",
    "\n",
    "# When computing the loss, we are ignoring cases when the label is the padding token\n",
    "for params in transformer.parameters():\n",
    "    if params.dim() > 1:\n",
    "        nn.init.xavier_uniform_(params)\n",
    "\n",
    "optim = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_INFTY = -1e9\n",
    "\n",
    "def create_masks(eng_batch, kn_batch):\n",
    "    num_sentences = len(eng_batch)\n",
    "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
    "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
    "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "\n",
    "    for idx in range(num_sentences):\n",
    "      eng_sentence_length, kn_sentence_length = len(eng_batch[idx]), len(kn_batch[idx])\n",
    "      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n",
    "      kn_chars_to_padding_mask = np.arange(kn_sentence_length + 1, max_sequence_length)\n",
    "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
    "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
    "      decoder_padding_mask_self_attention[idx, :, kn_chars_to_padding_mask] = True\n",
    "      decoder_padding_mask_self_attention[idx, kn_chars_to_padding_mask, :] = True\n",
    "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
    "      decoder_padding_mask_cross_attention[idx, kn_chars_to_padding_mask, :] = True\n",
    "\n",
    "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
    "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
    "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
    "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.train()\n",
    "transformer.to(device)\n",
    "total_loss = 0\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    iterator = iter(train_loader)\n",
    "    for batch_num, batch in enumerate(iterator):\n",
    "        transformer.train()\n",
    "        eng_batch, kn_batch = batch\n",
    "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, kn_batch)\n",
    "        optim.zero_grad()\n",
    "        kn_predictions = transformer(eng_batch,\n",
    "                                     kn_batch,\n",
    "                                     encoder_self_attention_mask.to(device), \n",
    "                                     decoder_self_attention_mask.to(device), \n",
    "                                     decoder_cross_attention_mask.to(device),\n",
    "                                     enc_start_token=False,\n",
    "                                     enc_end_token=False,\n",
    "                                     dec_start_token=True,\n",
    "                                     dec_end_token=True)\n",
    "        labels = transformer.decoder.sentence_embedding.batch_tokenize(kn_batch, start_token=False, end_token=True)\n",
    "        loss = criterian(\n",
    "            kn_predictions.view(-1, kn_vocab_size).to(device),\n",
    "            labels.view(-1).to(device)\n",
    "        ).to(device)\n",
    "        valid_indicies = torch.where(labels.view(-1) == kannada_to_index[PADDING_TOKEN], False, True)\n",
    "        loss = loss.sum() / valid_indicies.sum()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        #train_losses.append(loss.item())\n",
    "        if batch_num % 100 == 0:\n",
    "            print(f\"Iteration {batch_num} : {loss.item()}\")\n",
    "            print(f\"English: {eng_batch[0]}\")\n",
    "            print(f\"Kannada Translation: {kn_batch[0]}\")\n",
    "            kn_sentence_predicted = torch.argmax(kn_predictions[0], axis=1)\n",
    "            predicted_sentence = \"\"\n",
    "            for idx in kn_sentence_predicted:\n",
    "              if idx == kannada_to_index[END_TOKEN]:\n",
    "                break\n",
    "              predicted_sentence += index_to_kannada[idx.item()]\n",
    "            print(f\"Kannada Prediction: {predicted_sentence}\")\n",
    "\n",
    "\n",
    "            transformer.eval()\n",
    "            kn_sentence = (\"\",)\n",
    "            eng_sentence = (\"should we go to the mall?\",)\n",
    "            for word_counter in range(max_sequence_length):\n",
    "                encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, kn_sentence)\n",
    "                predictions = transformer(eng_sentence,\n",
    "                                          kn_sentence,\n",
    "                                          encoder_self_attention_mask.to(device), \n",
    "                                          decoder_self_attention_mask.to(device), \n",
    "                                          decoder_cross_attention_mask.to(device),\n",
    "                                          enc_start_token=False,\n",
    "                                          enc_end_token=False,\n",
    "                                          dec_start_token=True,\n",
    "                                          dec_end_token=False)\n",
    "                next_token_prob_distribution = predictions[0][word_counter] # not actual probs\n",
    "                next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
    "                next_token = index_to_kannada[next_token_index]\n",
    "                kn_sentence = (kn_sentence[0] + next_token, )\n",
    "                if next_token == END_TOKEN:\n",
    "                  break\n",
    "            \n",
    "            print(f\"Evaluation translation (should we go to the mall?) : {kn_sentence}\")\n",
    "            print(\"-------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sushil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
