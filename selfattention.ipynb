{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "L , d_k , d_v = 4,8,8\n",
    "\n",
    "q = np.random.randn(L , d_k)\n",
    "k = np.random.randn(L , d_k)\n",
    "v = np.random.randn(L , d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[ 1.76572456 -0.09270103  1.85045424  1.93527855 -1.70270076  0.88448396\n",
      "   0.63425415 -0.01749719]\n",
      " [ 1.07486017  0.06255792 -0.88694926  0.40140468 -0.67338265 -0.59566549\n",
      "  -0.57667649  0.08293533]\n",
      " [ 0.9830268  -1.29905319 -1.27460438 -0.07483937 -0.00826813 -0.78283928\n",
      "   0.16372286  0.61971329]\n",
      " [-0.88467336 -0.5604085   0.94750255 -1.62358875 -1.0599029  -0.6144543\n",
      "  -0.0409876   0.16435924]]\n",
      "K\n",
      " [[ 1.89160877  1.174909    1.87040293  0.48762916 -1.09535518  0.55980148\n",
      "  -1.47887525  2.27295813]\n",
      " [ 1.30067442  1.11379992 -1.24644673 -2.18297141  0.35262162 -1.05881751\n",
      "   1.20386723 -0.76781893]\n",
      " [ 0.34492372 -0.75682887 -0.5320155  -0.5253843  -1.47270244 -0.4158723\n",
      "  -1.17572458  0.85470216]\n",
      " [ 1.53277875  0.84089595 -0.47458492 -0.15825379 -0.91495678  0.78670665\n",
      "  -0.77250063 -1.30371231]]\n",
      "V\n",
      " [[ 0.76749538 -0.54523642  1.50417453  1.44480733 -0.59631405  0.48483205\n",
      "   0.02024295 -0.31996345]\n",
      " [ 0.92058135 -0.64767917  1.09034415 -0.37986402 -0.09516703 -0.04966115\n",
      "   0.62657242 -0.68457032]\n",
      " [ 0.53057917 -0.14639229 -0.33528961  0.38243035  1.27905306 -0.87575866\n",
      "  -0.6253887  -0.26123303]\n",
      " [ 1.09604623 -0.51322684  1.01204913  1.23002346 -0.35524795 -0.069254\n",
      "   1.50789757  1.75845304]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Q\\n\" , q)\n",
    "print(\"K\\n\" , k)\n",
    "print(\"V\\n\" , v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.01838249, -5.09769172,  0.0570399 ,  3.23062692],\n",
       "       [ 2.0889788 ,  1.33233073,  2.57268894,  2.54239762],\n",
       "       [-1.35000616,  2.13105255,  2.71457389, -0.5115581 ],\n",
       "       [-0.10018764,  0.68968995,  2.47303495, -1.71622925]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(q , k.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9080552617780995, 1.3393643336317367, 8.458295994928855)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()  , k.var() , np.matmul(q , k.T).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = np.matmul(q , k.T) / math.sqrt(d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9080552617780995, 1.3393643336317367, 1.0572869993661067)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()  , k.var() ,scaled.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking\n",
    "#### . This is to ensure words don't get context from words generated in the future.\n",
    "#### . Not required in the encoders, but required in the decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.tril(np.ones((L , L)))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[mask == 0] = -np.infty\n",
    "mask[mask == 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.18847971,        -inf,        -inf,        -inf],\n",
       "       [ 0.73856554,  0.47105005,        -inf,        -inf],\n",
       "       [-0.47729925,  0.75344085,  0.9597468 ,        -inf],\n",
       "       [-0.03542168,  0.24384222,  0.87434989, -0.60677867]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled + mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return (np.exp(x).T/np.sum(np.exp(x) , axis = -1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.56648286, 0.43351714, 0.        , 0.        ],\n",
       "       [0.11584789, 0.39663565, 0.48751646, 0.        ],\n",
       "       [0.18619651, 0.24618088, 0.46246654, 0.10515607]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = softmax(scaled + mask)\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84883198, 0.00577233, 0.03571419, 0.10968149],\n",
       "       [0.24238535, 0.18549229, 0.28759297, 0.2845294 ],\n",
       "       [0.10022987, 0.34316327, 0.421792  , 0.13481486],\n",
       "       [0.18619651, 0.24618088, 0.46246654, 0.10515607]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_v = np.matmul(attention , v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.76749538, -0.54523642,  1.50417453,  1.44480733, -0.59631405,\n",
       "         0.48483205,  0.02024295, -0.31996345],\n",
       "       [ 0.83386077, -0.58964711,  1.32477197,  0.65378102, -0.37905823,\n",
       "         0.25312009,  0.28309717, -0.47802678],\n",
       "       [ 0.71271418, -0.39142579,  0.4432656 ,  0.20315135,  0.51673106,\n",
       "        -0.39047738, -0.05402122, -0.43594749],\n",
       "       [ 0.73016552, -0.3826378 ,  0.49985682,  0.4817085 ,  0.41970286,\n",
       "        -0.33424314,  0.02736255, -0.16400372]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.76749538, -0.54523642,  1.50417453,  1.44480733, -0.59631405,\n",
       "         0.48483205,  0.02024295, -0.31996345],\n",
       "       [ 0.92058135, -0.64767917,  1.09034415, -0.37986402, -0.09516703,\n",
       "        -0.04966115,  0.62657242, -0.68457032],\n",
       "       [ 0.53057917, -0.14639229, -0.33528961,  0.38243035,  1.27905306,\n",
       "        -0.87575866, -0.6253887 , -0.26123303],\n",
       "       [ 1.09604623, -0.51322684,  1.01204913,  1.23002346, -0.35524795,\n",
       "        -0.069254  ,  1.50789757,  1.75845304]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return (np.exp(x).T/np.sum(np.exp(x) , axis = -1)).T\n",
    "\n",
    "def scaled_dot_product_attention(q , k , v , mask = None):\n",
    "    d_k = q.shape[-1]\n",
    "    scaled = np.matmul(q , k.T) / math.sqrt(d_k)\n",
    "    if mask is not None :\n",
    "        scaled = mask + scaled\n",
    "    attention  = softmax(scaled)\n",
    "    out = np.matmul(attention , v)\n",
    "    return out , attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[ 1.76572456 -0.09270103  1.85045424  1.93527855 -1.70270076  0.88448396\n",
      "   0.63425415 -0.01749719]\n",
      " [ 1.07486017  0.06255792 -0.88694926  0.40140468 -0.67338265 -0.59566549\n",
      "  -0.57667649  0.08293533]\n",
      " [ 0.9830268  -1.29905319 -1.27460438 -0.07483937 -0.00826813 -0.78283928\n",
      "   0.16372286  0.61971329]\n",
      " [-0.88467336 -0.5604085   0.94750255 -1.62358875 -1.0599029  -0.6144543\n",
      "  -0.0409876   0.16435924]]\n",
      "K\n",
      " [[ 1.89160877  1.174909    1.87040293  0.48762916 -1.09535518  0.55980148\n",
      "  -1.47887525  2.27295813]\n",
      " [ 1.30067442  1.11379992 -1.24644673 -2.18297141  0.35262162 -1.05881751\n",
      "   1.20386723 -0.76781893]\n",
      " [ 0.34492372 -0.75682887 -0.5320155  -0.5253843  -1.47270244 -0.4158723\n",
      "  -1.17572458  0.85470216]\n",
      " [ 1.53277875  0.84089595 -0.47458492 -0.15825379 -0.91495678  0.78670665\n",
      "  -0.77250063 -1.30371231]]\n",
      "V\n",
      " [[ 0.76749538 -0.54523642  1.50417453  1.44480733 -0.59631405  0.48483205\n",
      "   0.02024295 -0.31996345]\n",
      " [ 0.92058135 -0.64767917  1.09034415 -0.37986402 -0.09516703 -0.04966115\n",
      "   0.62657242 -0.68457032]\n",
      " [ 0.53057917 -0.14639229 -0.33528961  0.38243035  1.27905306 -0.87575866\n",
      "  -0.6253887  -0.26123303]\n",
      " [ 1.09604623 -0.51322684  1.01204913  1.23002346 -0.35524795 -0.069254\n",
      "   1.50789757  1.75845304]]\n",
      "New V\n",
      " [[ 0.76749538 -0.54523642  1.50417453  1.44480733 -0.59631405  0.48483205\n",
      "   0.02024295 -0.31996345]\n",
      " [ 0.83386077 -0.58964711  1.32477197  0.65378102 -0.37905823  0.25312009\n",
      "   0.28309717 -0.47802678]\n",
      " [ 0.71271418 -0.39142579  0.4432656   0.20315135  0.51673106 -0.39047738\n",
      "  -0.05402122 -0.43594749]\n",
      " [ 0.73016552 -0.3826378   0.49985682  0.4817085   0.41970286 -0.33424314\n",
      "   0.02736255 -0.16400372]]\n",
      "Attention\n",
      " [[1.         0.         0.         0.        ]\n",
      " [0.56648286 0.43351714 0.         0.        ]\n",
      " [0.11584789 0.39663565 0.48751646 0.        ]\n",
      " [0.18619651 0.24618088 0.46246654 0.10515607]]\n"
     ]
    }
   ],
   "source": [
    "values, attention = scaled_dot_product_attention(q, k, v, mask=mask)\n",
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)\n",
    "print(\"New V\\n\", values)\n",
    "print(\"Attention\\n\", attention)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sushil_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
